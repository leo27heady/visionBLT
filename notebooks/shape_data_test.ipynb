{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ce4eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leoni\\Documents\\projects\\visionBLT\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2865d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 17:49:34.418000 6952 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from shapekit import Scene, SceneType, Random2DShapeCreator\n",
    "\n",
    "from bytelatent.args import DataConfig, TemporalPatterns, IntervalModel\n",
    "from bytelatent.data.data_types import VisionBatch\n",
    "from bytelatent.data.shape_data_stream import ShapeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a8c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "data_config = DataConfig(\n",
    "    batch_size=4,\n",
    "    gradual_complexity=[1.0],\n",
    "    context_size=10,\n",
    "    time_to_pred=IntervalModel(min=1, max=1),\n",
    "    temporal_patterns=[]\n",
    ")\n",
    "data_loader = ShapeDataset(device, data_config, 0, 1)\n",
    "batch_iterator = data_loader.create_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e2ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_t torch.Size([1]) torch.int64 cuda:0\n",
      "images x torch.Size([4, 10, 1, 64, 64]) torch.int64 cuda:0\n",
      "images y torch.Size([4, 10, 1, 64, 64]) torch.int64 cuda:0\n",
      "angles torch.Size([4, 11]) torch.float32 cuda:0\n",
      "temp_patterns torch.Size([4, 4]) torch.float32 cuda:0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    batch = next(batch_iterator)\n",
    "\n",
    "    print(\"batch_t\", batch.batch_t.shape, batch.batch_t.dtype, batch.batch_t.device)\n",
    "    print(\"images x\", batch.x.shape, batch.x.dtype, batch.x.device)\n",
    "    print(\"images y\", batch.y.shape, batch.y.dtype, batch.y.device)\n",
    "    print(\"angles\", batch.angles.shape, batch.angles.dtype, batch.angles.device)\n",
    "    print(\"temp_patterns\", batch.temp_patterns.shape, batch.temp_patterns.dtype, batch.temp_patterns.device)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac59d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
