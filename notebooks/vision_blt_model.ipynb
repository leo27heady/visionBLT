{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4548ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leoni\\Documents\\projects\\visionBLT\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875ce71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420bc07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 21:38:27.163000 5140 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\leoni\\Documents\\projects\\visionBLT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from bytelatent.args import (\n",
    "    TrainArgs, \n",
    "    DataloaderArgs, OptimArgs, ByteLatentTransformerArgs, DistributedArgs, TokenizerArgs, PatcherArgs,\n",
    "    ProfilerArgs, CheckpointArgs, LoggingArgs\n",
    ")\n",
    "from bytelatent.checkpoint import SaveEvery\n",
    "from bytelatent.vision_model.local_models import LocalModelArgs, LocalEncoder\n",
    "from bytelatent.model.blt import (\n",
    "    get_encoder_dim_token_emb, get_encoder_dim_patch_emb, compute_hash_embeddings, cross_attn_mask, create_patch_mask_from_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404f17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainArgs(\n",
    "    name=\"debug\",\n",
    "    dump_dir=\"/tmp/\",\n",
    "    seed=777,\n",
    "    steps=100_000,\n",
    "    optim=OptimArgs(\n",
    "        lr=4e-04,\n",
    "        warmup=500,\n",
    "        lr_min_ratio=0.1,\n",
    "        clip=10.0\n",
    "    ),\n",
    "    distributed=DistributedArgs(\n",
    "        fsdp_type=\"full_shard\",\n",
    "        model_dtype=\"bf16\",\n",
    "        matmul_allow_tf32=False,\n",
    "        selective_activation_checkpointing=False,\n",
    "        tp_size=1\n",
    "    ),\n",
    "    model=ByteLatentTransformerArgs(\n",
    "        n_heads=8,\n",
    "        dim=512,\n",
    "        vocab_size=260,\n",
    "        dim_token=256,\n",
    "        patch_size=6,\n",
    "        patching_mode=\"space\",\n",
    "        tie_local_encoder_decoder_logits=False,\n",
    "        patch_in_forward=False,\n",
    "        max_encoder_seq_length=3072,\n",
    "        pad_to_max_length=True,\n",
    "        patching_threshold=3.1439168453216553,\n",
    "        encoder_hash_byte_group_size=None,\n",
    "        encoder_hash_byte_group_vocab=50002,\n",
    "        encoder_hash_byte_group_nb_functions=3,\n",
    "        encoder_enable_byte_ngrams=False,\n",
    "        cross_attn_encoder=True, # assuming cross_attention is true\n",
    "        cross_attn_decoder=True, # assuming cross_attention is true\n",
    "        cross_attn_window_encoder=None,\n",
    "        cross_attn_window_decoder=None,\n",
    "        dim_local_encoder=256,\n",
    "        dim_local_decoder=256,\n",
    "        cross_attn_k=2,\n",
    "        cross_attn_nheads=4,\n",
    "        cross_attn_all_layers_decoder=True,\n",
    "        cross_attn_all_layers_encoder=True,\n",
    "        cross_attn_use_flex_attention=False,\n",
    "        cross_attn_init_by_pooling=True,\n",
    "        log_patch_lengths=True,\n",
    "        non_linearity=\"swiglu\",\n",
    "        use_rope=True,\n",
    "        recompute_fc1_out=False,\n",
    "        recompute_fc3_out=False,\n",
    "        recompute_attn=False,\n",
    "        custom_bwd=False,\n",
    "        layer_ckpt=\"none\",\n",
    "        use_local_encoder_transformer=True,\n",
    "        init_use_gaussian=True,\n",
    "        init_use_depth=\"current\",\n",
    "        attn_impl=\"xformers\",\n",
    "        attn_bias_type=\"block_causal\",\n",
    "        alpha_depth=\"disabled\",\n",
    "        max_length=256,\n",
    "        local_attention_window_len=512,\n",
    "        downsampling_by_pooling=\"max\",\n",
    "    ),\n",
    "    data=DataloaderArgs(\n",
    "        root_dir=\".\",\n",
    "        sources={\"alpaca-cleaned\": 1.0},\n",
    "        dataset_files=[\"alpaca-cleaned/1.json\"],\n",
    "        batch_size=2,\n",
    "        prefetch_size=64,\n",
    "        seq_len=1024,\n",
    "        max_encoder_seq_length=3072,\n",
    "        load_async=False,\n",
    "        preprocess_dir=\"preprocess_dir\",\n",
    "        patcher_args=PatcherArgs(patching_mode=\"space\"),\n",
    "        tokenizer_args=TokenizerArgs(name=\"blt\"),\n",
    "    ),\n",
    "    profiling=ProfilerArgs(run=False),\n",
    "    checkpoint=CheckpointArgs(\n",
    "        path=\"train_checkpoints\",\n",
    "        dump=SaveEvery(\n",
    "            every=500,\n",
    "            keep=3\n",
    "        ),\n",
    "        eval=SaveEvery(\n",
    "            every=1000,\n",
    "            keep=-1\n",
    "        )\n",
    "    ),\n",
    "    logging=LoggingArgs(freq=10),\n",
    "    eval_on_gpus=1,\n",
    "    # env=None\n",
    ")\n",
    "\n",
    "args = train_args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5f9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_encoder_args = LocalModelArgs(\n",
    "    # Updated args\n",
    "    dim=args.dim_local_encoder,\n",
    "    n_layers=args.n_layers_local_encoder,\n",
    "    n_heads=args.n_heads_local_encoder,\n",
    "    dim_token_emb=get_encoder_dim_token_emb(args),\n",
    "    dim_patch_emb=get_encoder_dim_patch_emb(args),\n",
    "    cross_attn_encoder=args.cross_attn_encoder,\n",
    "    cross_attn_decoder=False,\n",
    "    cross_attn_k=args.cross_attn_k if args.cross_attn_encoder else None,\n",
    "    cross_attn_init_by_pooling=args.cross_attn_init_by_pooling,\n",
    "    # Defaults\n",
    "    head_dim=args.head_dim,\n",
    "    max_seqlen=args.max_encoder_seq_length,\n",
    "    dropout=args.dropout,\n",
    "    vocab_size=args.vocab_size + args.pm_size,\n",
    "    norm_eps=args.norm_eps,\n",
    "    patch_size=args.patch_size,\n",
    "    sliding_window=args.local_attention_window_len,\n",
    "    use_rope=args.use_rope,\n",
    "    rope_theta=args.rope_theta,\n",
    "    rope_use_fp32_in_outer_product=args.rope_use_fp32_in_outer_product,\n",
    "    init_base_std=args.init_base_std,\n",
    "    init_std_factor=args.init_std_factor,\n",
    "    n_kv_heads=args.n_kv_heads,\n",
    "    attn_impl=args.attn_impl,\n",
    "    attn_bias_type=\"local_block_causal\",\n",
    "    multiple_of=args.multiple_of,\n",
    "    ffn_dim_multiplier=args.ffn_dim_multiplier,\n",
    "    patching_mode=args.patching_mode,\n",
    "    use_local_encoder_transformer=args.use_local_encoder_transformer,\n",
    "    downsampling_by_pooling=args.downsampling_by_pooling,\n",
    "    encoder_hash_byte_group_size=args.encoder_hash_byte_group_size,\n",
    "    cross_attn_all_layers_encoder=args.cross_attn_all_layers_encoder,\n",
    "    cross_attn_all_layers_decoder=args.cross_attn_all_layers_decoder,\n",
    "    cross_attn_nheads=args.cross_attn_nheads,\n",
    "    eos_id=args.eos_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3741933",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_encoder = LocalEncoder(local_encoder_args).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b7e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wk): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wv): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wo): Linear(in_features=256, out_features=256, bias=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (w3): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (w2): Linear(in_features=768, out_features=256, bias=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn_norm): RMSNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (rope): RotaryEmbedding()\n",
       "  (patch_embedding_projection): Linear(in_features=256, out_features=512, bias=False)\n",
       "  (tok_embeddings): Embedding(260, 256)\n",
       "  (cross_attn_layers): ModuleList(\n",
       "    (0-7): 8 x CrossAttention(\n",
       "      (cross_attn_norm_q): RMSNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_attn_norm_kv): RMSNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (wq): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (wk): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (wv): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (wo): Linear(in_features=256, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fb861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1042ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([[1, 39, 39, 39, 39, 36]]).to(\"cuda\")\n",
    "bs, N = tokens.shape  # Batch size and sequence length\n",
    "\n",
    "local_encoder_tokens = tokens\n",
    "patch_ids = torch.tensor([[0, 1, 1, 2, 2, 3]]).to(\"cuda\")\n",
    "patch_lengths = torch.tensor([[1, 2, 2, 1]]).to(\"cuda\")\n",
    "local_encoder_embeds = None\n",
    "\n",
    "cross_attn_mask_enc = cross_attn_mask(\n",
    "    patch_ids,\n",
    "    patch_lengths,\n",
    "    N,\n",
    "    patches_as_queries=True,\n",
    "    cross_attn_k=args.cross_attn_k,\n",
    "    window=args.cross_attn_window_encoder,\n",
    "    block_mask=args.cross_attn_use_flex_attention,\n",
    ")\n",
    "\n",
    "(h_encoder, h_cross), cache_encoder = local_encoder(\n",
    "    tokens=local_encoder_tokens,\n",
    "    embeds=local_encoder_embeds,\n",
    "    patch_embeds=None,\n",
    "    cross_mask=cross_attn_mask_enc,\n",
    "    num_patches=patch_lengths.shape[1],\n",
    "    patch_ids=patch_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028bb123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 1, 2, 2, 3]], device='cuda:0'), 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_ids, patch_lengths.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03848028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 2, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46b89c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len = patch_ids.shape\n",
    "num_patches = patch_lengths.shape[1]\n",
    "\n",
    "q_ids = patch_ids.unsqueeze(-1).expand(bs, seq_len, num_patches)\n",
    "kv_ids = (\n",
    "    torch.arange(num_patches, device=patch_ids.device)\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(0)\n",
    "    .expand(bs, seq_len, num_patches)\n",
    ")\n",
    "# q_ids, kv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfb3027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False,  True, False],\n",
       "         [False, False,  True, False],\n",
       "         [False, False, False,  True]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ids==kv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c46d5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False],\n",
       "         [ True, False, False, False, False, False],\n",
       "         [False,  True,  True, False, False, False],\n",
       "         [False,  True,  True, False, False, False],\n",
       "         [False, False, False,  True,  True, False],\n",
       "         [False, False, False,  True,  True, False],\n",
       "         [False, False, False, False, False,  True],\n",
       "         [False, False, False, False, False,  True]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_mask = create_patch_mask_from_ids(\n",
    "    patch_ids,\n",
    "    patch_lengths.shape[1],\n",
    "    window=None,\n",
    "    patches_as_queries=True,\n",
    ").repeat_interleave(args.cross_attn_k, dim=1 if True else -1)\n",
    "cross_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35676d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 256]), torch.Size([1, 8, 256]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_encoder.shape, h_cross.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04fce6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [-inf, 0., 0., -inf, -inf, -inf],\n",
       "          [-inf, 0., 0., -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, 0., 0., -inf],\n",
       "          [-inf, -inf, -inf, 0., 0., -inf],\n",
       "          [-inf, -inf, -inf, -inf, -inf, 0.],\n",
       "          [-inf, -inf, -inf, -inf, -inf, 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_attn_mask_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86ff1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.0, -inf, -inf, -inf, -inf, -inf]\n",
      "1 [0.0, -inf, -inf, -inf, -inf, -inf]\n",
      "2 [-inf, 0.0, 0.0, -inf, -inf, -inf]\n",
      "3 [-inf, 0.0, 0.0, -inf, -inf, -inf]\n",
      "4 [-inf, -inf, -inf, 0.0, 0.0, -inf]\n",
      "5 [-inf, -inf, -inf, 0.0, 0.0, -inf]\n",
      "6 [-inf, -inf, -inf, -inf, -inf, 0.0]\n",
      "7 [-inf, -inf, -inf, -inf, -inf, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(cross_attn_mask_enc[0, 0]):\n",
    "    print(i, [float(x) for x in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6808a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fda6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371ace04",
   "metadata": {},
   "source": [
    "# Experiment with visionBLT attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29d7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "frames_batch = torch.tensor([\n",
    "    [\n",
    "        [\n",
    "            [111, 112, 113, 114],\n",
    "            [121, 122, 123, 124],\n",
    "            [131, 132, 133, 134],\n",
    "            [141, 142, 143, 144],\n",
    "        ],\n",
    "        [\n",
    "            [211, 212, 213, 214],\n",
    "            [221, 222, 223, 224],\n",
    "            [231, 232, 233, 234],\n",
    "            [241, 242, 243, 244],\n",
    "        ],\n",
    "        [\n",
    "            [311, 312, 313, 314],\n",
    "            [321, 322, 323, 324],\n",
    "            [331, 332, 333, 334],\n",
    "            [341, 342, 343, 344],\n",
    "        ],\n",
    "        [\n",
    "            [411, 412, 413, 414],\n",
    "            [421, 422, 423, 424],\n",
    "            [431, 432, 433, 434],\n",
    "            [441, 442, 443, 444],\n",
    "        ],\n",
    "        [\n",
    "            [511, 512, 513, 514],\n",
    "            [521, 522, 523, 524],\n",
    "            [531, 532, 533, 534],\n",
    "            [541, 542, 543, 544],\n",
    "        ]\n",
    "    ]\n",
    "]).to(\"cuda\")\n",
    "\n",
    "# Parameters\n",
    "batch_size, num_frames, height, width = frames_batch.shape\n",
    "frame_height  = 4\n",
    "frame_width   = 4\n",
    "tile_height   = 2\n",
    "tile_width    = 2\n",
    "patch_size    = 2   # number of consecutive frames sharing the same patch IDs\n",
    "device        = \"cuda\"\n",
    "\n",
    "# During the explanation the 4x4 frame with tile 2x2 will and patch size 2 be used for illustration\n",
    "# Compute how many tiles (patches) fit along each spatial axis\n",
    "tiles_y = height // tile_height\n",
    "tiles_x = width  // tile_width\n",
    "patches_per_frame = tiles_y * tiles_x\n",
    "\n",
    "# 1) Create a grid of patch indices\n",
    "tile_grid = torch.arange(patches_per_frame, device=device).view(tiles_y, tiles_x)\n",
    "# e.g. tile_grid = tensor([[0, 1],\n",
    "#                          [2, 3]])\n",
    "\n",
    "# 2) Expand each grid cell into a tile of size (tile_height x tile_width)\n",
    "#    Result: a (height x width) map where each entry is its patch index\n",
    "spatial_patch_map = (\n",
    "    tile_grid\n",
    "    .repeat_interleave(tile_height, dim=0)\n",
    "    .repeat_interleave(tile_width,  dim=1)\n",
    ")\n",
    "# spatial_patch_map.shape == (4, 4)\n",
    "# spatial_patch_map =\n",
    "# tensor([[0, 0, 1, 1],\n",
    "#         [0, 0, 1, 1],\n",
    "#         [2, 2, 3, 3],\n",
    "#         [2, 2, 3, 3]])\n",
    "\n",
    "# 3) Flatten the spatial map to shape (height*width,)\n",
    "flat_patch_ids = spatial_patch_map.view(-1)\n",
    "\n",
    "# 4) Compute a \"group index\" for each frame: \n",
    "frame_indices = torch.arange(num_frames, device=device)\n",
    "group_index  = frame_indices // patch_size  # shape: (T,)\n",
    "# [0//2, 1//2, 2//2, 3//2] = [0, 0, 1, 1]\n",
    "\n",
    "# 5) For each frame, add an offset of (group_index x patches_per_frame)\n",
    "#    to the base flat_patch_ids. Broadcasting yields shape (T, H*W)\n",
    "ids_per_frame = flat_patch_ids[None, :] + group_index[:, None] * patches_per_frame\n",
    "\n",
    "# 6) Reshape to a single vector per batch and repeat for all batches\n",
    "#    Final shape: (batch_size, T * height * width)\n",
    "patch_ids = (\n",
    "    ids_per_frame\n",
    "    .reshape(-1)             # (T*H*W,)\n",
    "    .unsqueeze(0)            # (1, T*H*W)\n",
    "    .expand(batch_size, -1)  # (B, T*H*W)\n",
    "    .to(device)\n",
    ")\n",
    "\n",
    "tokens = frames_batch.flatten(start_dim=1)  # Remain batch separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce267827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "938ce5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[111, 112, 113, 114, 121, 122, 123, 124, 131, 132, 133, 134, 141, 142,\n",
       "         143, 144, 211, 212, 213, 214, 221, 222, 223, 224, 231, 232, 233, 234,\n",
       "         241, 242, 243, 244, 311, 312, 313, 314, 321, 322, 323, 324, 331, 332,\n",
       "         333, 334, 341, 342, 343, 344, 411, 412, 413, 414, 421, 422, 423, 424,\n",
       "         431, 432, 433, 434, 441, 442, 443, 444, 511, 512, 513, 514, 521, 522,\n",
       "         523, 524, 531, 532, 533, 534, 541, 542, 543, 544]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76f724c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  1,  0,  0,  1,  1,  2,  2,  3,  3,  2,  2,  3,  3,  0,  0,\n",
       "          1,  1,  0,  0,  1,  1,  2,  2,  3,  3,  2,  2,  3,  3,  4,  4,  5,  5,\n",
       "          4,  4,  5,  5,  6,  6,  7,  7,  6,  6,  7,  7,  4,  4,  5,  5,  4,  4,\n",
       "          5,  5,  6,  6,  7,  7,  6,  6,  7,  7,  8,  8,  9,  9,  8,  8,  9,  9,\n",
       "         10, 10, 11, 11, 10, 10, 11, 11]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7f3e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.unique(patch_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59730676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  1,  0,  0,  1,  1,  2,  2,  3,  3,  2,  2,  3,  3,  0,  0,\n",
       "          1,  1,  0,  0,  1,  1,  2,  2,  3,  3,  2,  2,  3,  3,  4,  4,  5,  5,\n",
       "          4,  4,  5,  5,  6,  6,  7,  7,  6,  6,  7,  7,  4,  4,  5,  5,  4,  4,\n",
       "          5,  5,  6,  6,  7,  7,  6,  6,  7,  7,  8,  8,  9,  9,  8,  8,  9,  9,\n",
       "         10, 10, 11, 11, 10, 10, 11, 11]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "317f5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: True False False False False False False False False False False False \n",
      "1: True False False False False False False False False False False False \n",
      "2: False True False False False False False False False False False False \n",
      "3: False True False False False False False False False False False False \n",
      "4: True False False False False False False False False False False False \n",
      "5: True False False False False False False False False False False False \n",
      "6: False True False False False False False False False False False False \n",
      "7: False True False False False False False False False False False False \n",
      "8: False False True False False False False False False False False False \n",
      "9: False False True False False False False False False False False False \n",
      "10: False False False True False False False False False False False False \n",
      "11: False False False True False False False False False False False False \n",
      "12: False False True False False False False False False False False False \n",
      "13: False False True False False False False False False False False False \n",
      "14: False False False True False False False False False False False False \n",
      "15: False False False True False False False False False False False False \n",
      "16: True False False False False False False False False False False False \n",
      "17: True False False False False False False False False False False False \n",
      "18: False True False False False False False False False False False False \n",
      "19: False True False False False False False False False False False False \n",
      "20: True False False False False False False False False False False False \n",
      "21: True False False False False False False False False False False False \n",
      "22: False True False False False False False False False False False False \n",
      "23: False True False False False False False False False False False False \n",
      "24: False False True False False False False False False False False False \n",
      "25: False False True False False False False False False False False False \n",
      "26: False False False True False False False False False False False False \n",
      "27: False False False True False False False False False False False False \n",
      "28: False False True False False False False False False False False False \n",
      "29: False False True False False False False False False False False False \n",
      "30: False False False True False False False False False False False False \n",
      "31: False False False True False False False False False False False False \n",
      "32: False False False False True False False False False False False False \n",
      "33: False False False False True False False False False False False False \n",
      "34: False False False False False True False False False False False False \n",
      "35: False False False False False True False False False False False False \n",
      "36: False False False False True False False False False False False False \n",
      "37: False False False False True False False False False False False False \n",
      "38: False False False False False True False False False False False False \n",
      "39: False False False False False True False False False False False False \n",
      "40: False False False False False False True False False False False False \n",
      "41: False False False False False False True False False False False False \n",
      "42: False False False False False False False True False False False False \n",
      "43: False False False False False False False True False False False False \n",
      "44: False False False False False False True False False False False False \n",
      "45: False False False False False False True False False False False False \n",
      "46: False False False False False False False True False False False False \n",
      "47: False False False False False False False True False False False False \n",
      "48: False False False False True False False False False False False False \n",
      "49: False False False False True False False False False False False False \n",
      "50: False False False False False True False False False False False False \n",
      "51: False False False False False True False False False False False False \n",
      "52: False False False False True False False False False False False False \n",
      "53: False False False False True False False False False False False False \n",
      "54: False False False False False True False False False False False False \n",
      "55: False False False False False True False False False False False False \n",
      "56: False False False False False False True False False False False False \n",
      "57: False False False False False False True False False False False False \n",
      "58: False False False False False False False True False False False False \n",
      "59: False False False False False False False True False False False False \n",
      "60: False False False False False False True False False False False False \n",
      "61: False False False False False False True False False False False False \n",
      "62: False False False False False False False True False False False False \n",
      "63: False False False False False False False True False False False False \n",
      "64: False False False False False False False False True False False False \n",
      "65: False False False False False False False False True False False False \n",
      "66: False False False False False False False False False True False False \n",
      "67: False False False False False False False False False True False False \n",
      "68: False False False False False False False False True False False False \n",
      "69: False False False False False False False False True False False False \n",
      "70: False False False False False False False False False True False False \n",
      "71: False False False False False False False False False True False False \n",
      "72: False False False False False False False False False False True False \n",
      "73: False False False False False False False False False False True False \n",
      "74: False False False False False False False False False False False True \n",
      "75: False False False False False False False False False False False True \n",
      "76: False False False False False False False False False False True False \n",
      "77: False False False False False False False False False False True False \n",
      "78: False False False False False False False False False False False True \n",
      "79: False False False False False False False False False False False True \n"
     ]
    }
   ],
   "source": [
    "# ENCODER CROSS-ATTENTION\n",
    "bs, seq_len = patch_ids.shape\n",
    "num_patches = len(torch.unique(patch_ids))\n",
    "\n",
    "q_ids = patch_ids.unsqueeze(-1).expand(bs, seq_len, num_patches)\n",
    "kv_ids = (\n",
    "    torch.arange(num_patches, device=patch_ids.device)\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(0)\n",
    "    .expand(bs, seq_len, num_patches)\n",
    ")\n",
    "# q_ids, kv_ids\n",
    "\n",
    "counter = 0\n",
    "for line in (q_ids==kv_ids)[0]:\n",
    "    print(counter, end=\": \")\n",
    "    for el in line:\n",
    "        print(int(el) == 1, end=\" \")\n",
    "    print()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8067f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "1: False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "2: False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "3: False False False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "4: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "5: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "6: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False False False \n",
      "7: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False False False True True False False True True False False False False False False False False False False False False False False False False \n",
      "8: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False False False \n",
      "9: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False False False False False False False \n",
      "10: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True False False \n",
      "11: False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False True True False False True True \n"
     ]
    }
   ],
   "source": [
    "# DECODER CROSS-ATTENTION\n",
    "bs, seq_len = patch_ids.shape\n",
    "num_patches = len(torch.unique(patch_ids))\n",
    "\n",
    "kv_ids = patch_ids.unsqueeze(1).expand(bs, num_patches, seq_len)\n",
    "q_ids = (\n",
    "    torch.arange(num_patches, device=patch_ids.device)\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(-1)\n",
    "    .expand(bs, num_patches, seq_len)\n",
    ")\n",
    "# q_ids, kv_ids\n",
    "\n",
    "counter = 0\n",
    "for line in (q_ids==kv_ids)[0]:\n",
    "    print(counter, end=\": \")\n",
    "    for el in line:\n",
    "        print(int(el) == 1, end=\" \")\n",
    "    print()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "1: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "2: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "3: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "4: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "5: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "6: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "7: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "8: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "9: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "10: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "11: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "12: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "13: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "14: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "15: True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "16: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "17: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "18: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "19: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "20: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "21: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "22: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "23: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "24: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "25: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "26: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "27: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "28: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "29: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "30: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "31: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "32: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "33: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "34: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "35: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "36: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "37: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "38: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "39: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "40: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "41: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "42: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "43: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "44: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "45: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "46: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "47: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False \n",
      "48: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "49: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "50: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "51: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "52: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "53: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "54: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "55: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "56: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "57: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "58: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "59: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "60: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "61: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "62: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "63: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True False False False False False False False False False False False False False False False False \n",
      "64: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "65: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "66: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "67: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "68: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "69: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "70: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "71: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "72: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "73: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "74: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "75: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "76: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "77: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "78: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n",
      "79: True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True \n"
     ]
    }
   ],
   "source": [
    "# Causal-at-frame-level mask === Encoder - Decoder Mask\n",
    "# within each frame: full attention\n",
    "# between frames: only to current or any past frame (no future)\n",
    "\n",
    "bs, seq_len = patch_ids.shape\n",
    "frame_elements = frame_height * frame_width\n",
    "device       = \"cuda\"\n",
    "dtype        = torch.bfloat16\n",
    "\n",
    "block_full = torch.ones((frame_elements, frame_elements), device=device, dtype=dtype)\n",
    "block_causal = torch.tril(torch.ones((num_frames, num_frames), device=device, dtype=dtype))\n",
    "mask_causal_frames = torch.kron(block_causal, block_full)\n",
    "# → mask_causal_frames[i,j] == 1 iff\n",
    "#      frame_j ≤ frame_i   (where frame_* = index // frame_elements)\n",
    "\n",
    "# add optimization to have obsolete or decay in time the amount of connections (it should be automatically handled if have proper summary mechanism)\n",
    "\n",
    "counter = 0\n",
    "for line in mask_causal_frames:\n",
    "    print(counter, end=\": \")\n",
    "    for el in line:\n",
    "        print(int(el) == 1, end=\" \")\n",
    "    print()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fbcb34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102400"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32 * 10)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3909ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 32 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "561957b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: True True True True False False False False False False False False False False False False False False False False \n",
      "1: True True True True False False False False False False False False False False False False False False False False \n",
      "2: True True True True False False False False False False False False False False False False False False False False \n",
      "3: True True True True False False False False False False False False False False False False False False False False \n",
      "4: True True True True True True True True False False False False False False False False False False False False \n",
      "5: True True True True True True True True False False False False False False False False False False False False \n",
      "6: True True True True True True True True False False False False False False False False False False False False \n",
      "7: True True True True True True True True False False False False False False False False False False False False \n",
      "8: True True True True True True True True True True True True False False False False False False False False \n",
      "9: True True True True True True True True True True True True False False False False False False False False \n",
      "10: True True True True True True True True True True True True False False False False False False False False \n",
      "11: True True True True True True True True True True True True False False False False False False False False \n",
      "12: True True True True True True True True True True True True True True True True False False False False \n",
      "13: True True True True True True True True True True True True True True True True False False False False \n",
      "14: True True True True True True True True True True True True True True True True False False False False \n",
      "15: True True True True True True True True True True True True True True True True False False False False \n",
      "16: True True True True True True True True True True True True True True True True True True True True \n",
      "17: True True True True True True True True True True True True True True True True True True True True \n",
      "18: True True True True True True True True True True True True True True True True True True True True \n",
      "19: True True True True True True True True True True True True True True True True True True True True \n"
     ]
    }
   ],
   "source": [
    "# Causal-at-frame-level mask === Latent model Mask\n",
    "# within each frame: full attention\n",
    "# between frames: only to current or any past frame (no future)\n",
    "\n",
    "bs, seq_len = patch_ids.shape\n",
    "device       = \"cuda\"\n",
    "dtype        = torch.bfloat16\n",
    "\n",
    "block_full = torch.ones((patches_per_frame, patches_per_frame), device=device, dtype=dtype)\n",
    "block_causal = torch.tril(torch.ones((num_frames, num_frames), device=device, dtype=dtype))\n",
    "mask_causal_frames = torch.kron(block_causal, block_full)\n",
    "# → mask_causal_frames[i,j] == 1 iff\n",
    "#      frame_j ≤ frame_i   (where frame_* = index // patches_per_frame)\n",
    "\n",
    "counter = 0\n",
    "for line in mask_causal_frames:\n",
    "    print(counter, end=\": \")\n",
    "    for el in line:\n",
    "        print(int(el) == 1, end=\" \")\n",
    "    print()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf252a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52400a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e726b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d21580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
